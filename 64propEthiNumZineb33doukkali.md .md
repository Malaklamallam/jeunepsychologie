# Annotations  
(19/02/2026 17:01:34)

« Qu’est-ce qu’une éthique de l’IA ? Quelques propos introductifs » ([Maurel, p. 4](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=4&annotation=P5YNDTY7)) Je me demande si une éthique de l’IA doit être pensée comme un cadre fixe avec des règles précises, ou plutôt comme une réflexion évolutive qui dépend des contextes sociaux et des usages des technologies.

« dont il est devenu banal d’affirmer qu’elle doit être « responsable », « éthique », « de confiance ». » ([Maurel, p. 4](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=4&annotation=TPS8JKEQ)) Je trouve que ces termes comme “responsable” ou “éthique” sont souvent utilisés de manière trop générale dans les discours sur l’IA, sans que leur contenu concret soit vraiment précisé.

« Elle a été posée, frontalement, aux participantes et participants aux premières Assises nationales de l’éthique du numérique, dont le thème était précisément « l’éthique des systèmes d’IA ». » ([Maurel, p. 4](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=4&annotation=IXNZK96C)) Référence importante : ce passage montre que la réflexion sur l’éthique des systèmes d’IA s’inscrit dans un débat public et institutionnel plus large, et pas seulement dans un cadre technique

« le développement de systèmes d’IA serait intègre, à condition d’être transparent ; que ses avantages comme ses inconvénients soient publiquement connus ; et que ses biais fassent l’objet de communication et de tentatives de corrections respectueuses des deux autres piliers. » ([Maurel, p. 4](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=4&annotation=KUF8Y9DW)) Je suis d’accord avec cette idée, car la transparence me semble essentielle pour comprendre les effets réels des systèmes d’IA et permettre une confiance collective dans leur utilisation

« IA son développement respectueux du droit applicable et l’interrogation de ses concepteurs, sans nécessairement pouvoir tous les anticiper, à propos des mésusages possibles de leur création » ([Maurel, p. 4](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=4&annotation=QN72KY66)) Je suis d’accord avec cette idée, car elle rappelle que les concepteurs doivent réfléchir en amont aux risques et aux mésusages possibles des systèmes d’IA, même si tout ne peut pas être anticipé.

« Enfin, une IA serait durable si elle ne compromettait pas la capacité des générations futures à vivre, à exploiter différemment les ressources naturelles et à faire leurs propres choix au service de leur développement. » ([Maurel, p. 4](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=4&annotation=RBKDYCEW)) Je me demande comment on peut réellement mesurer la durabilité d’une IA sur le long terme, surtout quand ses impacts environnementaux et sociaux peuvent évoluer avec le temps et les usages.

« a Recommandation de l’UNESCO en inventorie par exemple 10, dont la plupart sont en réalité des doubles principes – est utile pour y voir plus clair, mais ne résout pas le problème de fond. » ([Maurel, p. 5](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=5&annotation=AW3SKSYJ)) Référence importante : ce passage rappelle que les cadres internationaux, comme ceux proposés par l’UNESCO, structurent la réflexion éthique sur l’IA, même s’ils ne suffisent pas à répondre à toutes les problématiques.

« Aussi est-il indispensable de sortir de cette approche, ou à tout le moins de ne pas limiter l’éthique de l’IA à une démarche de type principiste. » ([Maurel, p. 5](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=5&annotation=YQIKPAMB)) Je me demande ce que l’auteur propose concrètement à la place d’une approche seulement basée sur des principes, et comment cela peut être appliqué dans des situations réelles liées à l’IA.

« L’approche principielle est une solution de facilité : une fois un travail de réflexion autour des principes réalisé, ou des principes établis par d’autres réinvestis, il peut être tentant de tourner cette page pour se concentrer sur le développement, l’innovation, la réussite du modèle économique » ([Maurel, p. 5](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=5&annotation=K2K346WL)) Je suis d’accord avec cette analyse, car les principes éthiques peuvent parfois rester théoriques et être rapidement mis de côté face aux enjeux économiques et à la pression d’innover.

« [l]es acteurs économiques et les autorités publiques doivent faire preuve de prudence dans la vitesse d’adoption des systèmes d’IA générative et prévoir des évaluations préalables et continues »[5] » ([Maurel, p. 5](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=5&annotation=R5TH9SSH)) Je me demande comment définir concrètement une “vitesse d’adoption prudente” des IA génératives, surtout dans un contexte où les entreprises sont en concurrence et cherchent à innover rapidement.

« les limites éthiques au développement des systèmes de surveillance algorithmique, mettre l’IA au service de la science, concilier développement de l’IA et droits des travailleurs, mettre l’IA au service de la transparence de la gestion publique, concilier développement technologique et protection de l’environnement, les moyens éthiques pour lutter contre la désinformation en ligne. » ([Maurel, p. 5](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=5&annotation=SHB9GLSP)) Référence importante : cette liste montre les principaux enjeux éthiques identifiés par le livre blanc, notamment la surveillance, les droits des travailleurs, l’environnement et la transparence publique, ce qui donne une vision globale des domaines concernés par l’IA.

« Depuis ces travaux menés en avril 2025, la donne a-t-elle fondamentalement changé, s’agissant de l’éthique de l’IA ? » ([Maurel, p. 6](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=6&annotation=W6RQBA4A)) Je me demande si les principes éthiques évoluent vraiment avec les nouvelles générations d’IA, ou si les questions restent finalement les mêmes malgré les avancées technologiques.

« l’IA n’a toujours pas résolu la crise climatique (elle a plutôt tendance à l’aggraver), apporté la paix dans le monde ni fait considérablement évoluer l’humain d’un point de vue cognitif. » ([Maurel, p. 6](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=6&annotation=CP7GXHAH)) Je trouve que cette affirmation est un peu radicale, car elle semble attendre de l’IA qu’elle résolve des problèmes globaux très complexes qui dépassent largement le seul domaine technologique.

« le développement de modèles d’IA utiles au quotidien des collectivités, des chercheurs et des citoyennes et citoyens se poursuit, se dont il faut se féliciter » ([Maurel, p. 6](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=6&annotation=UIFKGF9X)) Je suis d’accord avec cette idée, car les systèmes d’IA peuvent aussi avoir des usages positifs dans la vie quotidienne, notamment pour la recherche, les services publics et les citoyens.

« On citera ainsi la Charte d’utilisation de l’IA au sein de la juridiction administrative, ou encore la Charte relative à l'utilisation de l'IA générative dans les services du Premier ministre de septembre 2025, qui indique des utilisations « proscrites » » ([Maurel, p. 6](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=6&annotation=2Y7TRIFG)) Référence importante : ce passage montre que des cadres institutionnels concrets commencent à encadrer l’usage de l’IA dans les administrations publiques, notamment à travers des chartes d’utilisation.

« Il n’est pas douteux, au regard de la vitesse d’adoption d’outil d’IA par toute entité publique ou privée – à la demande insistante des pouvoirs publics – depuis 2022, que de tels constats se multiplieront dans les semaines et mois à venir. » ([Maurel, p. 7](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=7&annotation=ZF3DXEZA)) Je ne suis pas totalement convaincue par cette affirmation, car elle semble présenter l’évolution des usages de l’IA comme inévitable sans vraiment prendre en compte les différences entre secteurs ou contextes d’adoption.

« le recours aux systèmes d’IA pourrait provoquer deux crises inédites dans la société. » ([Maurel, p. 32](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=32&annotation=YNSW38IJ)) Je me demande quelles sont précisément ces deux crises annoncées et si elles sont réellement nouvelles ou plutôt une transformation de problèmes sociaux déjà existants.

« LES conséquences d’une crise sur le marché du travail et les inégalités associées pourraient avoir un impact beaucoup plus important sur la civilisation humaine que la possible émergence d’une IA forte. » ([Maurel, p. 32](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=32&annotation=4CEH4W7Y)) Je trouve que cette comparaison entre les impacts sociaux du travail et l’émergence d’une IA forte est assez spéculative, car il reste difficile d’évaluer concrètement ces deux types de risques.

« L’évolution rapide des systèmes d’IA soulève des préoccupations majeures sur l’avenir des emplois. » ([Maurel, p. 32](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=32&annotation=N78UNJ8G)) Je me demande si les systèmes d’IA vont surtout supprimer certains emplois ou plutôt transformer les compétences demandées et les conditions de travail

« les activités professionnelles dans le domaine de la logistique sont très vulnérables » ([Maurel, p. 32](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=32&annotation=9UUCI9YE)) Je suis d’accord avec cette observation, car les métiers de la logistique semblent particulièrement exposés aux transformations liées à l’automatisation et à l’usage croissant des systèmes d’IA.

« La perspective d’une utilisation de drones dans le cadre d’activité de livraison pourrait aussi réduire les besoins en main-d’œuvre et entraîner des pertes d’emplois dans le processus de distribution . [ » ([Maurel, p. 32](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=32&annotation=2SAN569D)) Je ne suis pas totalement d’accord avec cette vision, car elle met surtout l’accent sur la perte d’emplois sans considérer les nouvelles formes de travail ou les adaptations possibles du secteur logistique.

« La perte d’emplois occasionnée par le développement et le recours plus fréquent aux systèmes d’IA pourrait favoriser la création de nouvelles professions » ([Maurel, p. 32](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=32&annotation=LQUUMS3V)) Je me demande si la création de nouvelles professions compensera réellement les pertes d’emplois liées à l’IA, ou si certains travailleurs risquent d’être exclus faute de formation adaptée.

« préoccupations et défis soulevés par l’intégration progressive des systèmes d’IA dans le monde du travail, la question qu’il convient de poser est de savoir comment concilier le développement de ces systèmes avec les droits reconnus aux travailleurs » ([Maurel, p. 33](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=33&annotation=ZMTZ49M8)) Je trouve que la question est pertinente, mais elle reste assez générale et ne précise pas concrètement quels droits des travailleurs sont les plus menacés par l’intégration des systèmes d’IA

« Les inquiétudes exprimées sur les outils d’IA portent essentiellement sur la perspective de réduction d’emplois. » ([Maurel, p. 33](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=33&annotation=X9K42XKA)) Je suis d’accord avec cette idée, car les débats autour de l’IA mettent souvent en avant la peur de la perte d’emplois, ce qui montre que les enjeux sociaux sont au cœur des préoccupations actuelles.

« l’impact des systèmes d'intelligence artificielle semble être beaucoup plus fort que ce que la première révolution industrielle a apporté. » ([Maurel, p. 33](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=33&annotation=NU9VUEL8)) Je trouve que cette comparaison avec la première révolution industrielle est un peu exagérée, car il est encore difficile d’évaluer l’ampleur réelle des transformations liées à l’IA sur le long terme.

« on retrouve la prohibition de toute forme de discrimination, la pertinence et le respect de la vie privée. » ([Maurel, p. 33](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=33&annotation=F93ETJLS)) Je suis d’accord avec ces principes, car la lutte contre la discrimination et le respect de la vie privée me semblent essentiels pour encadrer l’usage des systèmes d’IA dans le monde du travail.

« Le droit du travail reconnaît aussi l’existence d’un certain nombre d’obligations que l’employeur doit respecter. » ([Maurel, p. 33](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=33&annotation=B9GN3GJI)) Je me demande comment ces obligations du droit du travail peuvent être adaptées face à l’utilisation croissante des systèmes d’IA dans l’organisation et l’évaluation du travail.

« Au regard des règles existantes sur le fondement du droit du travail, il est impératif pour les entreprises d’envisager un développement éthique des systèmes d’IA, en prenant bien en compte les valeurs qui rendent acceptable leur utilisation. » ([Maurel, p. 34](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=34&annotation=N6IUTBXV)) Je trouve que l’idée d’un développement “éthique” reste assez vague ici, car le texte ne précise pas clairement quelles valeurs concrètes devraient guider les entreprises dans leurs choix.

« Il est intéressant de noter que cette approche éthique sur les systèmes d’IA repose sur deux aspects importants : la technique et l’impact sociétal. » ([Maurel, p. 34](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=34&annotation=IXZLWH5Z)) Je me demande comment trouver un équilibre réel entre l’aspect technique et l’impact sociétal, car les décisions technologiques semblent souvent prises avant une réflexion sociale approfondie.

« La mutation des emplois : Un accompagnement des salariés » ([Maurel, p. 35](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=35&annotation=HCGAWFYC)) Je me demande quels types d’accompagnement sont réellement envisagés pour les salariés et si ces mesures sont suffisantes pour faire face aux transformations rapides du travail liées à l’IA.

« Le comité social et économique désigne l’instance de représentation du personnel dans l’entreprise. Depuis le 1 janvier 2020, il fusionne l’ensemble des instances représentatives du personnel, délégués du personnel, comité d’entreprise et comité d’hygiène, de sécurité et des conditions de travail . L’ensemble de ses compétences, sa composition et son fonctionnement varient en fonction de la taille de l’entreprise. Il doit être mis en place dans les entreprises comprenant au moins 11 salariés » ([Maurel, p. 35](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=35&annotation=KTW88GES)) Référence importante : ce passage rappelle le rôle du comité social et économique comme acteur clé dans la représentation des salariés, notamment face à l’introduction de nouvelles technologies comme les systèmes d’IA dans l’entreprise.

« Procéder à la réalisation d’un audit sur les systèmes d’IA en entreprise. » ([Maurel, p. 35](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=35&annotation=DWZB88BB)) Référence importante : cette proposition souligne l’importance des audits pour évaluer les impacts éthiques et sociaux des systèmes d’IA avant et pendant leur utilisation en entreprise.

« Promouvoir la responsabilité des entreprises en matière d’usage des systèmes d’IA. » ([Maurel, p. 36](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=36&annotation=2J9UF65U)) Référence importante : ce passage met en avant la responsabilité des entreprises dans le développement et l’usage des systèmes d’IA, en soulignant que les enjeux éthiques ne concernent pas seulement la technique mais aussi la gouvernance

« Permettre l’ouverture d’un dialogue social au sein de l’entreprise, afin de renforcer les stratégies d’encadrement de l’IA au sein de l’entreprise. » ([Maurel, p. 37](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=37&annotation=P9SULFZ4)) Référence importante : ce passage insiste sur le rôle du dialogue social comme outil essentiel pour encadrer l’usage de l’IA en entreprise et prendre en compte les préoccupations des salariés.

« Adopter un ensemble de règles générales de bonne conduite au sein de l’entreprise. » ([Maurel, p. 37](zotero://select/library/items/R2MXFDV6)) ([pdf](zotero://open-pdf/library/items/MIXWXMCH?page=37&annotation=FFRR6KCC)) Référence importante : cette proposition montre la volonté d’encadrer l’usage de l’IA par des règles collectives afin de guider les pratiques professionnelles et limiter les dérives possibles.