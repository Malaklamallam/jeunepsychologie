# Annotations  
(12/02/2026 17:09:20)

« il n’y a jamais de technologie en soi » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=5&annotation=F7HZI87Y)) Est-ce que les outils numériques peuvent vraiment être neutres s’ils sont toujours liés à un contexte social ?

« Ce sont plutôt des conditions d’appropriation, toujours contingentes et hétérogènes, qui permettent d’établir un lien entre ces deux formes de progrès. » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=5&annotation=NUH2JRUX)) Je trouve que cette idée reste abstraite et ne montre pas clairement comment ces conditions fonctionnent dans la réalité.

« l’éthique nous invite à intégrer le fait que ce qui est technologiquement possible n’est pas toujours humainement ou socialement souhaitable. » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=5&annotation=B8H4HPKL)) Comment décider concrètement ce qui est socialement souhaitable lorsque les contextes culturels et sociaux sont différents ?

« C’est pourquoi l’intérêt pour le comportement éthique des agents autonomes est apparu dans les travaux de recherche traitant des agents autonomes, comme en témoignent déjà, à leur façon, les rapports internationaux ou nationaux publiés à ce jour234. » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=5&annotation=6RGKRACY)) Je suis d’accord : l’éthique devient une dimension essentielle dans le développement des agents autonomes

« L’éthique nous invite à intégrer le fait que ce qui est technologiquement possible n’est pas toujours humainement ou socialement souhaitable. » ([“Ethique et agents autonomes”, p. 5](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=5&annotation=ZWHXHWLY)) Concept clé pour comprendre la différence entre progrès technique et impact social.

« « La morale se présente comme un ensemble de règles contraignantes d’un type spécial, qui consiste à juger des actions et des intentions en les rapportant à des valeurs transcendantes (c’est bien, c’est mal...) ; » ([“Ethique et agents autonomes”, p. 6](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=6&annotation=BHE3GLQK)) Cette définition de la morale me semble réductrice, car elle présente les règles comme uniquement contraignantes sans considérer les dimensions culturelles ou sociales plus nuancées.

« la morale est universelle, elle commande de façon inconditionnelle (si nous suivons par exemple l’impératif catégorique de Kant) et s’impose à ce titre, ou devrait s’imposer, à tous. » ([“Ethique et agents autonomes”, p. 6](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=6&annotation=7QDERUM2)) Je ne suis pas totalement d’accord avec l’idée d’une morale universelle valable pour toutes les situations

« le bon et le mauvais pour nous. L’éthique est constituée de l’ensemble réfléchi de nos désirs. » ([“Ethique et agents autonomes”, p. 6](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=6&annotation=GSRTDR7N)) Si l’éthique repose sur des désirs réfléchis, comment construire des règles communes dans des sociétés où les valeurs et les désirs sont différents ?

« quels sont les éléments permettant d’apprécier une situation lorsqu’il est question d’éthique et d’agents autonomes ? » ([“Ethique et agents autonomes”, p. 6](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=6&annotation=RLTQTCX6)) Comment évaluer une décision prise par une machine sans ignorer le contexte humain ?

« En effet, ce n’est pas parce que des concepts éthiques sont modélisés et mis en œuvre dans une application que les usages de cette dernière seront éthiques par construction. » ([“Ethique et agents autonomes”, p. 7](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=7&annotation=UN62AS9W)) Une technologie peut-elle vraiment rester éthique une fois utilisée dans des contextes différents ?

« les choix que nous avons dû opérer. Le chapitre 3 détaille les réalisations techniques du projet ETHICAA. » ([“Ethique et agents autonomes”, p. 7](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=7&annotation=E2HQPM5A)) J’ai l’impression que la dimension technique prend ici le dessus sur la réflexion éthique.

« Le travail réalisé par le projet ETHICAA ne prémunit pas les applications d’une évaluation par un comité d’éthique. » ([“Ethique et agents autonomes”, p. 7](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=7&annotation=K2ZDPYNJ)) Référence importante : rappelle que les outils techniques ne remplacent pas l’évaluation humaine et institutionnelle des enjeux éthiques.

« Les « valeurs » ou « cadres éthiques » représentés et simulés dans une machine constituent bien des représentations, des simplifications, » ([“Ethique et agents autonomes”, p. 9](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=9&annotation=SEG4WTPU)) Une machine peut-elle vraiment représenter des valeurs humaines sans les déformer ?

« Il convient de permettre une élucidation scrupuleuse des modes de vie qui se voient engagés car nos interactions avec des agents autonomes ne sont pas sans conséquences d’un point de vue existentiel. » ([“Ethique et agents autonomes”, p. 9](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=9&annotation=KF7S6E5D)) Je suis d’accord : les agents autonomes ont un impact réel sur nos façons de vivre et doivent être analysés avec attention.

« il n’y a pas de risque technologique en soi mais des contextes (sociaux, économiques ou politiques) qui favorisent, ou non, une appropriation clairvoyante des objets technologiques. » ([“Ethique et agents autonomes”, p. 9](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=9&annotation=536DC9I5)) Je ne suis pas totalement d’accord : certaines technologies peuvent aussi créer des risques indépendamment du contexte.

« Les armes létales autonomes Le débat est engagé à l’ONU à Genève, dans le cadre de la Convention sur certaines armes classiques (CCAC), sur la question d’une interdiction ou d’un moratoire sur le développement des armes autonomes. Loin de prendre ici une quelconque position, il s’agit avant tout de savoir précisément de quoi on parle. En premier lieu, « autonome » a des acceptions multiples : plutôt que de parler d’ « arme autonome », il semble plus pertinent d’étudier quelles fonctions sont, ou pourront être, automatisées, et avec quelles limitations. En second lieu, une arme n’est pas forcément létale – et une arme létale, quel que soit son niveau d’automatisation, n’est en aucun cas animée d’une intention de tuer. » ([“Ethique et agents autonomes”, p. 10](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=10&annotation=37D5JLKF)) Cas d’étude important pour comprendre les enjeux éthiques et politiques des agents autonomes.

« Ces différences témoignent de l’impossibilité d’établir, pour cet exemple particulier, des principes éthiques universels. Pour les Anciens, les termes morale (mores en latin) et éthique (ethos en grec) signifiaient la même chose et étaient la traduction l’un de l’autre. L’usage les distingue, voire les oppose, aujourd’hui. » ([“Ethique et agents autonomes”, p. 11](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=11&annotation=Y5S7G5PA))

« C’est cet usage du terme qui est invoqué dans les implications éthiques de la technologie moderne. » ([“Ethique et agents autonomes”, p. 12](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=12&annotation=FGMH7C9C)) Comment éviter que certains termes éthiques soient utilisés de manière trop vague ou stratégique dans le discours technologique ?

« Il est alors essentiel de distinguer responsabilité et culpabilité. » ([“Ethique et agents autonomes”, p. 12](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=12&annotation=ACU6UGNZ)) Je trouve que cette distinction est intéressante mais peut être difficile à appliquer concrètement.

« Pour être moralement responsable, il doit y avoir une « intention coupable ». » ([“Ethique et agents autonomes”, p. 12](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=12&annotation=A6KHELFT)) Je suis d’accord : l’intention joue un rôle essentiel pour comprendre la responsabilité morale.

« Les notions de responsabilité morale, d’intention, d’autonomie, de volonté dépendent toutes à des degrés divers de la notion plus fondamentale de liberté. » ([“Ethique et agents autonomes”, p. 13](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=13&annotation=XIUDN9WS)) Concept clé pour comprendre le lien entre liberté et responsabilité des agents autonomes.

« Cette liberté renferme l’exigence d’une autonomie absolue, c’est l’existence qui précède l’essence » ([“Ethique et agents autonomes”, p. 13](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=13&annotation=H8TU6RKB)) Peut-on vraiment parler d’autonomie pour une machine comme pour un humain ?

« Pour Spinoza, le libre arbitre n’existe pas. Si les humains se figurent être libres, c’est parce qu’ils ont conscience de leur désir mais ignorent tout des causes qui leur font désirer. C’est la nécessité qui s’impose à nous » ([“Ethique et agents autonomes”, p. 13](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=13&annotation=F2ATPTWB)) Je ne suis pas totalement d’accord avec cette idée, car elle limite trop la notion de liberté et de responsabilité humaine.

« Finalement, l’agent autonome libre est celui qui se possède par la réflexion, celui qui compare, analyse, prévoit et juge les différentes séries de phénomènes. » ([“Ethique et agents autonomes”, p. 14](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=14&annotation=97ISQQYF)) Cette définition me paraît pertinente car elle insiste sur la capacité réflexive comme élément central de l’autonomie, ce qui permet de distinguer une simple automatisation d’une véritable prise de décision.

« Jugement Un point important, et malheureusement trop souvent omis, porte sur le jugement entendu au sens classique de l’opération de connaissance qui fait passer de sensations ou de perceptions à un concept. Un individu qui aurait perdu l’usage de ses sens ou serait victime d’hallucinations ne serait pas nécessairement en mesure de porter un jugement sur une situation » ([“Ethique et agents autonomes”, p. 14](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=14&annotation=HW5JCXED)) Cette définition du jugement me semble très centrée sur une conception classique de la perception, et elle peut être difficile à transposer aux systèmes techniques qui fonctionnent selon d’autres formes de traitement de l’information.

« Cependant, le choix lui-même est fait par l’agent à partir de données et de règles, ce qui fait que, même s’il paraît décider de lui-même, il ne fait qu'exécuter le code informatique mis en place par ses programmeurs. » ([“Ethique et agents autonomes”, p. 17](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=17&annotation=ZXYACBQW)) Une machine peut-elle être considérée comme libre si elle ne fait qu’exécuter du code ?

« Il s’ensuit des prises de positions dans le débat sociétal, scientifique et technique assez fortement divergentes dès lors qu’on cherche à appliquer une ou plusieurs valeurs sociales à des agents autonomes. » ([“Ethique et agents autonomes”, p. 17](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=17&annotation=58MI8MWG)) Cette idée souligne la diversité des points de vue, mais elle ne propose pas vraiment de méthode pour gérer concrètement ces divergences dans la conception des systèmes autonomes.

« La première distinction que nous opérons est entre morale et éthique, c’est-à-dire entre le raisonnement sur le bien et mal, et le raisonnement sur le juste et l’injuste comme vu au chapitre précédent. » ([“Ethique et agents autonomes”, p. 19](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=19&annotation=MGNPI3CI)) Je suis d’accord : distinguer morale et éthique permet de mieux analyser les décisions des agents autonomes.

« L’identification automatique d’un dilemme en tant que tel est une tâche complexe et néanmoins pertinente. » ([“Ethique et agents autonomes”, p. 19](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=19&annotation=EC6HQ6MK)) Comment une machine peut-elle reconnaître qu’une situation constitue réellement un dilemme éthique sans compréhension du contexte humain ?

« Qu’il s’agisse d’identifier un dilemme ou de raisonner sur ce dilemme, il est important de toujours garder à l’esprit les limites de perception d’un agent. » ([“Ethique et agents autonomes”, p. 20](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=20&annotation=SGHEMK6S)) Je ne suis pas totalement d’accord : les dilemmes éthiques ne dépendent pas seulement des limites de perception d’un agent.

« Constituant un bloc important d’un cadre de raisonnement éthique, la causalité est une notion subtile qui a été et reste amplement discutée en philosophie. » ([“Ethique et agents autonomes”, p. 21](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=21&annotation=C3DWS34J)) Je trouve que cette idée reste trop abstraite et difficile à appliquer aux agents autonomes.

« Événements causés et événements évités » ([“Ethique et agents autonomes”, p. 22](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=22&annotation=WZRETSFV)) Concept clé pour comprendre les conséquences des actions et des non-actions des agents autonomes.

« Le choix d’un agent dans une situation donnée peut se traduire par une action, mais aussi par une inaction. Or, il est des cas où l’inaction endosse sans conteste un poids moral. » ([“Ethique et agents autonomes”, p. 22](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=22&annotation=B2N7TD59)) Je ne suis pas totalement d’accord : l’inaction n’a pas toujours la même signification morale selon les situations.

« Un modèle du juste qui détermine l’action éthiquement la plus adaptée selon des circonstances données, le champ des possibles et les désirs des agents. » ([“Ethique et agents autonomes”, p. 23](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=23&annotation=ZKK3XVIU)) Je ne suis pas convaincue qu’un seul modèle puisse définir ce qui est juste dans toutes les situations

« « Il ne faut jamais mentir » ou « Il ne faut pas utiliser les autres pour ses propres fins » » ([“Ethique et agents autonomes”, p. 24](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=24&annotation=WJY2QEBD)) Ces principes moraux me semblent pertinents car ils rappellent l’importance du respect de l’autre et des limites éthiques fondamentales dans les interactions humaines et technologiques.

« Un modèle de jugement éthique a été intégré au sein d’une architecture réflexive d’agent de type « Belief/Desire/Intention ». » ([“Ethique et agents autonomes”, p. 24](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=24&annotation=XEL26IAR)) Je ne suis pas sûr(e) que l’éthique puisse vraiment être intégrée dans une architecture technique sans perdre sa complexité.

« La justice prédictive La notion de justice prédictive peut s’entendre d’au moins trois façons, selon que l’on s’intéresse au jugement, auquel cas cela peut avoir deux significations, ou à la législation. » ([“Ethique et agents autonomes”, p. 25](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=25&annotation=XCZ3ZZCV)) Je trouve que la justice prédictive peut être dangereuse si elle remplace le jugement humain par des statistiques.

« jugement aveugle (l'agent juge utilise ses propres théories uniquement), 2. partiellement informé (l’agent juge se fonde sur une connaissance partielle des théories de l’agent jugé), 3. totalement informé (l'agent juge se fonde sur une connaissance totale). » ([“Ethique et agents autonomes”, p. 26](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=26&annotation=WKTCRKY2)) Je trouve que ces catégories sont un peu trop simplifiées par rapport aux situations réelles.

« Pour ce faire, nous avons proposé un nouveau modèle de jeux de coalitions – les jeux de déviation hédoniques – où chaque agent exprime des conditions qui lui sont propres pour caractériser la manière dont il tient compte des autres agents. » ([“Ethique et agents autonomes”, p. 27](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=27&annotation=SJXZS7PV)) Contribution importante du projet pour modéliser les relations entre agents autonomes.

« Le modèle en question présente notamment l’avantage d’être associé à une plate-forme qui permet de faire le travail de génération des obligations de preuve et de vérification automatiquement dans la plupart des cas. » ([“Ethique et agents autonomes”, p. 30](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=30&annotation=U98MJBXL)) Je trouve que l’automatisation peut donner l’illusion d’une décision neutre alors qu’elle dépend toujours de choix humains.

« Les réflexions de Norbert Wiener peuvent à cet égard constituer une source importante d’inspiration. » ([“Ethique et agents autonomes”, p. 32](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=32&annotation=IPIKT8QS))

« Du besoin de modularité Un processus de raisonnement s’appuyant sur une représentation explicite des considérations éthiques doit permettre une expression claire et générale de ces considérations. » ([“Ethique et agents autonomes”, p. 33](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=33&annotation=MWATXPQ2)) Un processus de raisonnement (…) doit permettre une expression claire et générale de ces considérations [éthiques].

« un être humain peut choisir de ne pas agir de façon morale : jusqu’où traduire cela dans un algorithme, programmer la dérogation aux règles, la transgression ? » ([“Ethique et agents autonomes”, p. 35](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=35&annotation=KD94ZHN7)) Est-il éthique de programmer la possibilité de transgresser des règles dans une machine, alors que la responsabilité morale reste humaine ?

« Du raisonnement éthique sous contrainte de temps de calcul limité » ([“Ethique et agents autonomes”, p. 40](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=40&annotation=JEVKP4SL)) Cette idée me semble pertinente, car elle rappelle que les décisions éthiques des agents autonomes sont aussi limitées par des contraintes techniques réelles comme le temps de calcul.

« Cette tension est intéressante dans le sens où elle est très éloignée du scénario classique fort prisé du grand public et largement imaginaire (le célèbre dilemme du trolley) où la voiture doit choisir entre le sacrifice du passager et celui d’un groupe de jeunes gens insouciants traversant par inadvertance la rue au feu vert. » ([“Ethique et agents autonomes”, p. 42](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=42&annotation=SBBNKNJJ)) Les exemples médiatiques comme le dilemme du trolley reflètent-ils vraiment les problèmes éthiques concrets ?

« La certification pourra-t-elle prendre en compte les conditions de déploiement du système avec notam44 ment les interactions avec d'autres produits, que ces interactions soient prévues ou non ? La certification pourra-elle prendre en compte l'évolution du système artificiel lorsque, par exemple, celui-ci est équipé de capacités d'apprentissage automatique ? » ([“Ethique et agents autonomes”, p. 44](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=44&annotation=SCZMYLWW)) Une certification peut-elle vraiment garantir l’éthique d’une IA qui continue d’apprendre après sa mise en service ?

« Aucune éthique ne peut s’élaborer indépendamment d’une discussion ouverte et contradictoire. » ([“Ethique et agents autonomes”, p. 47](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=47&annotation=DS3QEKBD)) Référence importante : principe fondamental qui rappelle que l’éthique repose sur le débat collectif et ne peut être réduite à une simple modélisation technique.

« C’est ce qu’une écologie de l’action montre clairement : dans la pratique, l’intention risque le plus souvent de se traduire par un échec dans la mesure où les effets de l’action dépendent non seulement des intentions de celui qui agit, mais aussi des contextes où l’action se déroule. » ([“Ethique et agents autonomes”, p. 48](zotero://select/library/items/C3X5FB6R)) ([pdf](zotero://open-pdf/library/items/2Y2KH7JN?page=48&annotation=THNN5RIG)) Comment intégrer dans les systèmes techniques le fait que les effets réels d’une action peuvent dépasser les intentions initiales des concepteurs ?